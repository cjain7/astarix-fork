configfile: "snakemake_config.yaml"

BCALM = config["bcalm_bin_path"]
BCALMCONVERTPATH = config["bcalm_convert_path"]
ART = config["art_bin_path"]
PBSIM = config["pbsim_bin_path"]
RANDOMREADS = config["randomreads_path"]

ASTARIX_BIN = config["astarix_bin_path"]
GA_BIN = config["graphaligner_bin_path"]
PASGAL_BIN = config["pasgal_bin_path"]
VG_BIN = config["vg_bin_path"]
VARGAS_BIN = config["vargas_bin_path"]

TIMELIMIT       = "(timeout 7200s"
TIMEOUTPRINT    = ") || ([ $? -eq 124 ] && echo timeouted)"

ASTARIX_PREFIX_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-prefix -q {input.reads} -g {input.graph} -d 5 -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
#ASTARIX_SEEDS_EXACT_SHORT_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_MATCH_POS_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds --seeds_match_pos_optimization 0 -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_SKIP_NEAR_CRUMBS_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds --seeds_skip_near_crumbs 0 -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_OPT_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds --seeds_match_pos_optimization 0 --seeds_skip_near_crumbs 0 -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_APPROX_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds --seeds_max_errors 1 -q {input.reads} -g {input.graph} -M 0 -S 1 -G 5 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
DIJKSTRA_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a dijkstra -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
GA_CMD = "{TIMELIMIT} {GA_BIN} --seeds-first-full-rows 64 -b 10000 -a alignments.gaf -f {input.reads} -g {input.graph_vg} >{output.file} {TIMEOUTPRINT} >>{output.file}"
PASGAL_CMD = "{TIMELIMIT} {PASGAL_BIN} -m vg -r {input.graph_vg} -q {input.reads} -t 1 -o {output.file} {TIMEOUTPRINT} >>{output.file}"
VARGAS_CMD = "{TIMELIMIT} {VARGAS_BIN} align -g {input.graph_gdef} -U {input.reads} --ete >{output.align} 2>{output.file} {TIMEOUTPRINT}"
### VG_CMD = inlined ### "{TIMELIMIT} {VG_BIN} align -s \"${ary[1]}\" {input.graph_vg} >{output.align} 2>{output.file} {TIMEOUTPRINT}"

PaSGAL_DATA_URL = "https://alurulab.cc.gatech.edu/sites/all/projectFiles/PaSGAL_Chirag"
PaSGAL_FILES = ["L1.fa", "L2.fastq", "L3.fastq",
                "M1.fa", "M2.fastq", "M3.fastq",
                "LRC.vg", "MHC1.vg", "MHC2.txt"]

# params

REF_SIZE_ALGOS          = ["astarix-seeds"] #, "astarix-prefix", "vargas", "graphaligner", "pasgal", "dijkstra"] #"vg", 
REF_SIZE_SCALING_GRAPHS = ["ecoli"]
REF_SIZE_GRAPH_HEADS    = [10000, 100000, 1000000, 10000000]
REF_SIZE_Ns             = [10000]  # number of reads
REF_SIZE_SEQ_TECHNOLOGY = ["illumina"]
REF_SIZE_ms             = [150]

READLEN_ALGOS           = ["astarix-seeds"] #, "vargas"] #, "dijkstra"] #, "vargas"] "astarix-prefix", "dijkstra"] , "graphaligner", "vg", "pasgal",# "astarix-seeds-approx"]
READLEN_SCALING_GRAPHS  = ["ecoli"]
READLEN_GRAPH_HEADS     = [10000000]
READLEN_Ns              = [200]
READLEN_SEQ_TECHNOLOGY  = ["hifi"] #"ccs", "illumina", 
READLEN_ms              = [100, 2000, 7000, 15000, 25000] # [100, 300, 700, 1000, 2000] #, 3000, 5000, 7000, 10000, 13000, 15000, 18000, 20000]
#READLEN_ms              = [50, 100, 150, 200, 250, 300, 500, 700, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 7000, 10000]
#READLEN_ms              = [50, 100, 150, 160, 170, 180, 200, 250]

ABLATION_ALGOS			= ["astarix-seeds", "astarix-seeds_wo_skip_near_crumbs_pos", "astarix-seeds_wo_match_pos", "astarix-seeds_wo_opt", "vargas"]
ABLATION_SCALING_GRAPHS = ["ecoli"]
ABLATION_GRAPH_HEADS    = [10000000]
ABLATION_Ns             = [200]
ABLATION_SEQ_TECHNOLOGY = ["hifi"] #"ccs", "illumina", 
ABLATION_ms             = [100, 2000, 7000, 10000, 15000, 20000] # [100, 300, 700, 1000, 2000] #, 3000, 5000, 7000, 10000, 13000, 15000, 18000, 20000]

NUMREADS_ALGOS          = ["astarix-seeds", "astarix-prefix", "vargas"] #, "graphaligner"]
NUMREADS_SCALING_GRAPHS = ["ecoli"]
NUMREADS_GRAPH_HEADS    = [1000000000]
NUMREADS_Ns             = [1000, 10000, 100000, 1000000]
NUMREADS_SEQ_TECHNOLOGY  = ["illumina"] #, "ccs"]
NUMREADS_ms             = [100]

GRAPHS       = [ "ecoli" ] #"chr1" ]# "ecoli" ]
ALGOS        = ["astarix-seeds", "astarix-prefix" ] # [ "pasgal", "astarix", "dijkstra", "graphaligner" ] # ] #, "dijkstra", "graphaligner" ] #"vg" ] $"pasgal"
GRAPH_HEADS_SMALL  = [10000, 100000, 1000000, 10000000]  # up to current exact state-of-the-art
GRAPH_HEADS_BIG    = [10000000, 100000000, 100000000]
GRAPH_HEADS = GRAPH_HEADS_SMALL #+ GRAPH_HEADS_BIG
Ns           = [10000] #, 1000, 10000]       # number of reads
ms           = [100] #75] #, 100, 150, 250]          # read len

FIRST_ROW       = "algo\tgraph\thead\tN\tm\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
AGGREGATED_BENCHMARKS = "results/aggregated_benchmarks.csv"
AGGREGATED_EXPERIMENTS = "results/aggregated_experiments.csv"

graph_params = "{graph}_head{head}"
read_params = "N{N}_m{m}_{seq_technology}"
params = graph_params + "_" + read_params

EXPERIMENT_N = 1000 #20000
EXPERIMENT_FIRST_ROW       = "algo\tgraph\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
EXPERIMENT_GRAPHS = ["MHC1", "LRC"]
EXPERIMENT_READS = { "MHC1": "M1", "LRC": "L1", "ecoli": "ecoli"}
experiment_graph = "graphs/pasgal-{graph}.gfa"
experiment_graph_vg = "raw/PaSGAL/{graph}.vg"
experiment_input_reads = "raw/PaSGAL/{reads}.fa"

aligners_inputs = {
    'graph' : "graphs/"+graph_params+"_linear.gfa",
    'graph_vg' : "graphs/"+graph_params+"_linear.vg",
    'reads' : "reads/"+params+"/reads.fq"
}

## Default summary rule to be satisfied.
rule all:
    input:
#        agg1 = "results/aggregated_benchmarks.csv"
        ref_size = "results/REF_SIZE_SCALING_DONE",
        readlen = "results/READLEN_SCALING_DONE",
        ablation = "results/ABLATION_SCALING_DONE",
#        numreads = "results/NUMREADS_SCALING_DONE"
#        astar_prefix_vs_seeds = "results/PREFIX_VS_SEEDS_RAN",
#        visualization = "results/VISUALIZATION_RAN",
#        agg2 = "results/aggregated_experiments.csv",
#        trie = "results/TRIE_DUMMY"

rule refsize_experiment:
    input:
        refs = expand("prefixes/"+graph_params+".fa", graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms, seq_technology=REF_SIZE_SEQ_TECHNOLOGY),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms, seq_technology=REF_SIZE_SEQ_TECHNOLOGY),
    output:
        "results/REF_SIZE_SCALING_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule readlen_experiment:
    input:
        refs = expand("prefixes/"+graph_params+".fa", graph=READLEN_SCALING_GRAPHS, head=READLEN_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=READLEN_ALGOS, graph=READLEN_SCALING_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms, seq_technology=READLEN_SEQ_TECHNOLOGY),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=READLEN_ALGOS, graph=READLEN_SCALING_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms, seq_technology=READLEN_SEQ_TECHNOLOGY),
    output:
        "results/READLEN_SCALING_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=READLEN_ALGOS, graph=READLEN_SCALING_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule ablation_experiment:
    input:
        refs = expand("prefixes/"+graph_params+".fa", graph=ABLATION_SCALING_GRAPHS, head=ABLATION_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=ABLATION_ALGOS, graph=ABLATION_SCALING_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms, seq_technology=ABLATION_SEQ_TECHNOLOGY),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ABLATION_ALGOS, graph=ABLATION_SCALING_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms, seq_technology=ABLATION_SEQ_TECHNOLOGY),
    output:
        "results/ABLATION_SCALING_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=ABLATION_ALGOS, graph=ABLATION_SCALING_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

#rule numreads_scaling_experiment:
#    input:
#        refs = expand("prefixes/"+graph_params+".fa", graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS),
#        reads = expand("reads/"+params+"/reads.fq", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms),
#        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms),
#    output:
#        "results/NUMREADS_SCALING_DONE"
#    params:
#        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

#rule trie_experiments:
#    input:
#        expand("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE", D=range(6, 17))
#    output:
#        "results/TRIE_DUMMY"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute trie_experiment.ipynb > {output}"
#
#rule trie_experiment:
#    input:
#        "results/aggregated_benchmarks.csv"
#    output:
#        dir = directory("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}/"),
#        dummy = "results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE"
#    shell:
#        "{ASTARIX_BIN} align-optimal -D {wildcards.D} -t 1 -g graphs/ecoli_head1000000_linear.gfa -q reads/ecoli_head1000000_N1000_m100/illumina.fq -o {output.dir} && touch {output.dummy}"

#rule aggregate_benchmarks:
#    input:
#        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms),
#    output:
#        "results/aggregated_benchmarks.csv"
#    params:
#        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"

#rule aggregate_experiments:
#    input:
#        file = expand("results/{algo}/{graph}/benchmark.txt", algo=ALGOS, graph=EXPERIMENT_GRAPHS),
#    output:
#        "results/aggregated_experiments.csv"
#    params:
#        prefix = expand("{algo}\t{graph}", algo=ALGOS, graph=EXPERIMENT_GRAPHS)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{EXPERIMENT_FIRST_ROW}\\n/' > {output}"

#rule visualization_notebook:
#    input:
#        aggregated_benchmarks = "results/aggregated_benchmarks.csv",
#    output:
#        "results/VISUALIZATION_RAN"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute visualization.ipynb > {output}"

rule astar_prefix_vs_seeds:
    input:
        astar_prefix_align = "results/astarix-prefix/MHC1/out/alignments.tsv",
        astar_seeds_align = "results/astarix-seeds/MHC1/out/alignments.tsv"
    output:
        "results/PREFIX_VS_SEEDS_RAN"
    shell:
        "jupyter nbconvert --to notebook --inplace --execute astar_vs_dijkstra.ipynb > {output}"

rule astarix_prefix:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-prefix/"+params+"/out/alignments.tsv",
        file = "results/astarix-prefix/"+params+"/summary.txt"
    benchmark:
        "results/astarix-prefix/"+params+"/benchmark.txt"
    log:
        "results/astarix-prefix/"+params+"/log.txt"
    shell:
        ASTARIX_PREFIX_CMD

rule astarix_seeds_exact:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds/"+params+"/summary.txt"
	#priority: 100 
    benchmark:
        "results/astarix-seeds/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_CMD

rule astarix_seeds_wo_match_pos:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds_wo_match_pos/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_match_pos/"+params+"/summary.txt"
	#priority: 100 
    benchmark:
        "results/astarix-seeds_wo_match_pos/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_match_pos/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_MATCH_POS_CMD

rule astarix_seeds_wo_skip_near_crumbs_pos:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/summary.txt"
	#priority: 100 
    benchmark:
        "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_SKIP_NEAR_CRUMBS_CMD

rule astarix_seeds_wo_opt:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds_wo_opt/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_opt/"+params+"/summary.txt"
	#priority: 100 
    benchmark:
        "results/astarix-seeds_wo_opt/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_opt/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_OPT_CMD

rule astarix_seeds_approx:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds-approx/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds-approx/"+params+"/summary.txt"
	#priority: 100 
    benchmark:
        "results/astarix-seeds-approx/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds-approx/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_APPROX_CMD

rule dijkstra:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/dijkstra/"+params+"/out/alignments.tsv",
        file = "results/dijkstra/"+params+"/summary.txt"
    benchmark:
        "results/dijkstra/"+params+"/benchmark.txt"
    log:
        "results/dijkstra/"+params+"/log.txt"
    shell:
        DIJKSTRA_CMD

#rule benchmark_dijkstra:
#    input:
#        reads = lambda wlc: "reads/"+EXPERIMENT_READS[wlc.graph]+"_reads"+str(EXPERIMENT_N)+".fa",
#        graph = "graphs/pasgal-{graph}.gfa",
#    output:
#        align = "results/dijkstra/{graph}/out/alignments.tsv",
#        file = "results/dijkstra/{graph}/summary.txt"
#    benchmark:
#        "results/dijkstra/{graph}/benchmark.txt"
#    log:
#        "results/dijkstra/{graph}/log.txt"
#    shell:
#        DIJKSTRA_CMD

rule vargas:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_gdef = "prefixes/"+graph_params+".gdef"
    output:
        align = "results/vargas/"+params+"/out/alignments.tsv",
        file = "results/vargas/"+params+"/summary.txt"
    benchmark:
        "results/vargas/"+params+"/benchmark.txt"
    log:
        "results/vargas/"+params+"/log.txt"
    shell:
        VARGAS_CMD

rule prepare_vargas_graph:
    input:
        "prefixes/"+graph_params+".fa"
    output:
        "prefixes/"+graph_params+".gdef"
    shell:
        "{VARGAS_BIN} define -f {input} -t {output}"

rule graphaligner:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_vg = "graphs/"+graph_params+"_linear.vg"
        #graph = "prefixes/"+graph_params+".fa"
    output:
        file = "results/graphaligner/"+params+"/summary.txt"
    benchmark:
        "results/graphaligner/"+params+"/benchmark.txt"
    log:
        "results/graphaligner/"+params+"/log.txt"
    shell:
        GA_CMD

rule pasgal:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_vg = "graphs/"+graph_params+"_linear.vg"
        #reads = lambda wlc: "reads/"+EXPERIMENT_READS[wlc.graph]+"_reads"+str(EXPERIMENT_N)+".fa",
        #graph = "graphs/pasgal-{graph}.gfa",
    output:
        file = "results/pasgal/"+params+"/summary.txt"
    benchmark:
        "results/pasgal/"+params+"/benchmark.txt"
    log:
        "results/pasgal/"+params+"/log.txt"
    shell:
        PASGAL_CMD

rule vg2gfa:
    input:
        "raw/PaSGAL/{prefix}.vg"
    output:
        "graphs/pasgal-{prefix}.gfa"
    shell:
        "{VG_BIN} view {input} > {output}"

## Chronological order of execution follows. ##

rule clean:
    shell:
        "rm -rf reads graphs prefixes"

rule download_ecoli:
    output:
        protected("raw/ecoli.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-40/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz"),
        shell("gunzip Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz")
        shell("cut -d ' ' -f 1 < Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa >{output}")

rule download_chr1:
    output:
        protected("raw/chr1.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("gunzip Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("cut -d ' ' -f 1 < Homo_sapiens.GRCh38.dna.chromosome.1.fa | sed 's/[nN]//g' >{output}")

rule download_PaSGAL_data:
    output:
        protected("raw/PaSGAL/{file}")
    shadow: "shallow"
    run:
        shell("wget {PaSGAL_DATA_URL}/{wildcards.file} -O {output}")

rule create_genome_prefix:
    input:
        "raw/{graph}.fa"
    output:
        "prefixes/"+graph_params+".fa"
    run:
        if {wildcards.head}:
            shell("head -c {wildcards.head} {input} >{output}")
        else:
            shell("cp {input} {output}")
        #"echo -n 'S\t1\t' >{output} && tail -n +2 {input} | tr -d '\n' >>{output}"
        #"| head -c {wildcards.head} >>{output}"

rule create_linear_graph:
    input:
        "prefixes/"+graph_params+".fa"
    output:
        gfa = "graphs/"+graph_params+"_linear.gfa",
        vg = "graphs/"+graph_params+"_linear.vg"
    shell:
        "echo -n 'S\t1\t' >{output.gfa} && tail -n +2 {input} | tr -d '\n' >>{output.gfa} && echo -n '\nS\t2\tA\nL\t1\t+\t2\t+\t0M\n' >>{output.gfa}"  # make PaSGAL happy: add a fictive segment
        "&& {VG_BIN} view -Fv {output.gfa} >{output.vg}"
		
# art_illumina -ss MSv3 -i ecoli.fasta -l 20 -c 10000 -o tmp
#    "reads/"+params+"/reads.fq"

rule simmulate_illumina_reads:
    input:
        "prefixes/"+graph_params+".fa"
    params:
        prefix = "reads/"+graph_params+"_N{N}_m{m}_illumina/reads"
    output:
        "reads/"+graph_params+"_N{N}_m{m}_illumina/reads.fq"
    shadow: "shallow"
    shell:
        "{ART} -ss MSv3 -sam -i {input} -c {wildcards.N} -l {wildcards.m} -o {params.prefix} --rndSeed 42"

rule simulate_ccs_reads:
	input:
		"prefixes/"+graph_params+".fa"
	params:
		prefix = "reads/"+graph_params+"_N{N}_m{m}_ccs/reads"
	output:
		"reads/"+graph_params+"_N{N}_m{m}_ccs/reads.fq"
	shadow: "shallow"
	run:
		shell("{PBSIM} --data-type CLR --depth 0.02 --model_qc pbsim_profiles/model_qc_clr --length-min {wildcards.m} --length-max {wildcards.m} --length-mean {wildcards.m} --accuracy-min 0.99 --accuracy-sd 0 --accuracy-mean 1 {input}")
		#shell("{PBSIM} --hmm_model pbsim_models/P4C2.model --depth 0.001 --accuracy-min 0.99 --accuracy-max 0.99 --accuracy-mean 0.99 --accuracy-sd 0 --length-mean {wildcards.m} --length-sd 0 {input}")
		#"{PBSIM} --sample-fastq pbsim_sample.fastq --depth 0.001 --accuracy-min 0.98 --accuracy-max 0.98 --length-mean {wildcards.m} --length-sd 0 {input}"
		#"{PBSIM} --data-type CCS --depth 0.001 --model_qc pbsim_profiles/model_qc_ccs --length-mean {wildcards.m} --length-sd 0 {input}"
		shell("cp -L sd_0001.fastq {params.prefix}.fq")
		shell("cp -L sd_0001.maf {params.prefix}.maf")
		shell("cp -L sd_0001.ref {params.prefix}.ref")

rule simulate_hifi_reads:
	input:
		"prefixes/"+graph_params+".fa"
	params:
		prefix = "reads/"+graph_params+"_N{N}_m{m}_hifi/reads"
	output:
		"reads/"+graph_params+"_N{N}_m{m}_hifi/reads.fq"
	shadow: "shallow"
	shell:
		#"{RANDOMREADS} build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin=0.003 pbmax=0.003 coverage=0.02 paired=f minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"
		"{RANDOMREADS} build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin=0.003 pbmax=0.003 coverage=0.02 paired=f gaussianlength=t minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"

#ruleorder: head_ecoli_reads > head_reads

rule head_reads:
    input:
        "raw/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

rule head_pasgal_reads:
    input:
        "raw/PaSGAL/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

#rule run_astarix_prefix:
#    input: **aligners_inputs
#    output:
#        file = "results/astarix-prefix/"+params+"/summary.txt",
#        align = "results/astarix-prefix/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/astarix-prefix/"+params+"/benchmark.txt"
#    log:
#        "results/astarix-prefix/"+params+"/log.txt"
#    shell:
#        ASTARIX_PREFIX_CMD
#
#rule run_astarix_seeds:
#    input: **aligners_inputs
#    output:
#        file = "results/astarix-seeds/"+params+"/summary.txt",
#        align = "results/astarix-seeds/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/astarix-seeds/"+params+"/benchmark.txt"
#    log:
#        "results/astarix-seeds/"+params+"/log.txt"
#    shell:
#        ASTARIX_SEEDS_CMD
#
#rule run_dijkstra:
#    input: **aligners_inputs
#    output:
#        file = "results/dijkstra/"+params+"/summary.txt",
#        align = "results/dijkstra/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/dijkstra/"+params+"/benchmark.txt"
#    log:
#        "results/dijkstra/"+params+"/log.txt"
#    shell:
#        DIJKSTRA_CMD
#
#rule run_graphaligner:
#    input: **aligners_inputs
#    output:
#        file = "results/graphaligner/"+params+"/summary.txt"
#    benchmark:
#        "results/graphaligner/"+params+"/benchmark.txt"
#    log:
#        "results/graphaligner/"+params+"/log.txt"
#    shell:
#        GA_CMD
#
#rule run_pasgal:
#    input: **aligners_inputs
#    output:
#        file = "results/pasgal/"+params+"/summary.txt"
#    benchmark:
#        "results/pasgal/"+params+"/benchmark.txt"
#    log:
#        "results/pasgal/"+params+"/log.txt"
#    shell:
#        PASGAL_CMD

rule vg:
	input: **aligners_inputs
	output:
		file = "results/vg/"+params+"/summary.txt",
		align = "results/vg/"+params+"/alignments.tsv"
	benchmark:
		"results/vg/"+params+"/benchmark.txt"
	shell:
		"{TIMELIMIT} while mapfile -t -n 4 ary && ((${{#ary[@]}})); do {VG_BIN} align -s \"${{ary[1]}}\" {input.graph_vg} -j; done <{input.reads} >{output.align} 2>{output.file} {TIMEOUTPRINT}"
		#query = "AAACGT",
		#shell(VG_CMD)

