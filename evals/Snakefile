configfile: "snakemake_config.yaml"

BCALM = config["bcalm_bin_path"]
BCALMCONVERTPATH = config["bcalm_convert_path"]
ART = config["art_bin_path"]
PBSIM = config["pbsim_bin_path"]
RANDOMREADS = config["randomreads_path"]

ASTARIX_BIN = config["astarix_bin_path"]
GA_BIN = config["graphaligner_bin_path"]
PASGAL_BIN = config["pasgal_bin_path"]
VG_BIN = config["vg_bin_path"]
VARGAS_BIN = config["vargas_bin_path"]

TIMELIMIT       = "(timeout 3600s"
TIMEOUTPRINT    = ") || ([ $? -eq 124 ] && echo -e \"timeout\ntimeout\" >{log}) || (echo -e \"exit error code\n$?\" | tee {log})"

DIJKSTRA_CMD								= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a dijkstra     -D 14 -M 0 -S 1 -G 5                                                             -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_PREFIX_ILLUMINA_CMD					= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-prefix -D 14 -M 0 -S 1 -G 5 -d 5                                                        -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_PREFIX_CMD							= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-prefix -D 14 -M 0 -S 1 -G 1 -d 5                                                        -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_ILLUMINA_CMD 					= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 5 --seeds_len 25                                                            -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
#ASTARIX_SEEDS_EXACT_SHORT_CMD 				= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50                                              -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_CMD 					= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50                                              -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_MATCH_POS_CMD		= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50 --seeds_match_pos_optimization 0             -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_SKIP_NEAR_CRUMBS_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50 --seeds_skip_near_crumbs 0                   -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_APPROX_CMD					= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50 --seeds_max_errors 1                         -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_EXACT_WO_OPT_CMD				= "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds  -D 14 -M 0 -S 1 -G 1 --seeds_len 50 --seeds_match_pos_optimization 0 --seeds_skip_near_crumbs 0 -q {input.reads} -g $(echo {input.graph} | sed 's|_head100000000_|_head0_|g') -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
GA_CMD = "{TIMELIMIT} {GA_BIN} --seeds-first-full-rows 64 -b 10000 -t 1 -a alignments.gaf -f {input.reads} -g {input.graph_vg} >{output.file} {TIMEOUTPRINT} >>{output.file}"
PASGAL_CMD = "{TIMELIMIT} {PASGAL_BIN} -m vg -r {input.graph_vg} -q {input.reads} -t 1 -o {output.file} {TIMEOUTPRINT} >>{output.file}"
VARGAS_CMD = "{TIMELIMIT} {VARGAS_BIN} align -g {input.graph_gdef} -U {input.reads} --ete >{output.align} 2>{output.file} {TIMEOUTPRINT}"

PaSGAL_DATA_URL = "https://alurulab.cc.gatech.edu/sites/all/projectFiles/PaSGAL_Chirag"
PaSGAL_FILES = ["L1.fa", "L2.fastq", "L3.fastq",
                "M1.fa", "M2.fastq", "M3.fastq",
                "LRC.vg", "MHC1.vg", "MHC2.txt"]

# LINEAR GENOMES USED FOR:
# -- PaSGAL does not accept .gaf and bi-directional .vg;
# -- Vargas does not accept .gaf and .vg but only .gdef that can be build by .fa

TABLE_ILLUMINA_ALGOS          = ["astarix-seeds-illumina", "graphaligner", "pasgal", "vargas", "astarix-prefix-illumina", "dijkstra"]
TABLE_ILLUMINA_GRAPHS         = ["MHC1", "ecoli"] #, "LRC"]
TABLE_ILLUMINA_GRAPH_HEADS    = [100000000]
TABLE_ILLUMINA_Ns             = [1000]  # number of reads
TABLE_ILLUMINA_SEQ_TECHNOLOGY = ["illumina"]
TABLE_ILLUMINA_ms             = [200]
TABLE_ILLUMINA_errors         = [-1]

TABLE_HIFI_ALGOS          = ["astarix-seeds", "graphaligner", "vargas", "pasgal", "dijkstra", "astarix-prefix"]
TABLE_HIFI_GRAPHS         = ["MHC1", "ecoli"]
TABLE_HIFI_GRAPH_HEADS    = [100000000]
TABLE_HIFI_Ns             = [0.1]  # number of reads
TABLE_HIFI_SEQ_TECHNOLOGY = ["hifi-natural"]
TABLE_HIFI_ms             = [0]
TABLE_HIFI_errors         = [0.003]

REF_SIZE_ALGOS          = ["astarix-seeds-illumina", "vargas", "graphaligner", "pasgal"] #, "astarix-prefix-illumina", ] # "dijkstra"
REF_SIZE_GRAPHS         = ["MHC1"]
REF_SIZE_GRAPH_HEADS    = [5000, 50000, 500000, 5000000]
REF_SIZE_Ns             = [100000]  # number of reads
REF_SIZE_SEQ_TECHNOLOGY = ["illumina"]
REF_SIZE_ms             = [200]
REF_SIZE_errors         = [-1]

#reference scaling experiment on HiFi

READLEN_ALGOS           = ["astarix-seeds", "graphaligner", "pasgal", "vargas"]
READLEN_GRAPHS          = ["MHC1"]  #["ecoli"]
READLEN_GRAPH_HEADS     = [10000000]  # 0 stands for the .gfa graph version, not the linear .fa
READLEN_Ns              = [0.03]
READLEN_SEQ_TECHNOLOGY  = ["hifi"] #"ccs"
READLEN_ms              = [2000, 7000, 15000, 25000]
READLEN_errors          = [0.003]

# NOT USED
ABLATION_ALGOS          = ["astarix-seeds"] #, "astarix-seeds_wo_match_pos"] #, "astarix-seeds_wo_skip_near_crumbs_pos", "astarix-seeds_wo_opt", "vargas"]
ABLATION_GRAPHS         = ["MHC1"] #["ecoli"]
ABLATION_GRAPH_HEADS    = [100000000]
ABLATION_Ns             = [200]
ABLATION_SEQ_TECHNOLOGY = ["hifi"] #"ccs", "illumina",
ABLATION_ms             = [100, 2000, 7000, 10000, 15000, 20000] #, 25000, 30000] # [100, 300, 700, 1000, 2000] #, 3000, 5000, 7000, 10000, 13000, 15000, 18000, 20000]
ABLATION_errors         = [0.003]

# NOT USED
ERRORRATE_ALGOS          = ["astarix-seeds"] #, "astarix-seeds_wo_match_pos"]
ERRORRATE_GRAPHS         = ["MHC1"]
ERRORRATE_GRAPH_HEADS    = [0]
ERRORRATE_Ns             = [0.03]
ERRORRATE_SEQ_TECHNOLOGY = ["hifi"] #"ccs", "illumina",
ERRORRATE_ms             = [2000] # [100, 300, 700, 1000, 2000] #, 3000, 5000, 7000, 10000, 13000, 15000, 18000, 20000]
ERRORRATE_errors         = [0.003, 0.005, 0.01, 0.02, 0.03]

FIRST_ROW       = "algo\tgraph\thead\tN\tm\tsequencing_technology\terrorrate\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
AGGREGATED_BENCHMARKS = "results/aggregated_benchmarks.csv"
AGGREGATED_EXPERIMENTS = "results/aggregated_experiments.csv"

graph_params = "{graph}_head{head}"
read_params = "N{N}_m{m}_{seq_technology}_errors{errors}"
params = graph_params + "_" + read_params

#EXPERIMENT_N = 1000 #20000
#EXPERIMENT_FIRST_ROW       = "algo\tgraph\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
#EXPERIMENT_GRAPHS = ["MHC1", "LRC"]
#EXPERIMENT_READS = { "MHC1": "M1", "LRC": "L1", "ecoli": "ecoli"}

#experiment_graph = "graphs/pasgal-{graph}.gfa"
#experiment_graph_vg = "raw/PaSGAL/{graph}.vg"
#experiment_input_reads = "raw/PaSGAL/{reads}.fa"

aligners_inputs = {
    'graph' : "graphs/"+graph_params+".gfa",
    'graph_vg' : "graphs/"+graph_params+".vg",
    'reads' : "reads/"+params+"/reads.fq"
}

## Default summary rule to be satisfied.
rule all:
    input:
#        agg1 = "results/aggregated_benchmarks.csv"
        table_illumina = "results/TABLE_ILLUMINA_DONE",
        table_hifi = "results/TABLE_HIFI_DONE",
        ref_size = "results/REF_SIZE_DONE",
        readlen = "results/READLEN_DONE",
        ablation = "results/ABLATION_DONE",
        errorrate = "results/ERRORRATE_DONE",
#        numreads = "results/NUMREADS_DONE"
#        astar_prefix_vs_seeds = "results/PREFIX_VS_SEEDS_RAN",
#        visualization = "results/VISUALIZATION_RAN",
#        agg2 = "results/aggregated_experiments.csv",
#        trie = "results/TRIE_DUMMY"

rule table_illumina_exp:
    input:
        refs = expand("graphs/"+graph_params+".fa", graph=TABLE_ILLUMINA_GRAPHS, head=TABLE_ILLUMINA_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=TABLE_ILLUMINA_ALGOS, graph=TABLE_ILLUMINA_GRAPHS, head=TABLE_ILLUMINA_GRAPH_HEADS, N=TABLE_ILLUMINA_Ns, m=TABLE_ILLUMINA_ms, seq_technology=TABLE_ILLUMINA_SEQ_TECHNOLOGY, errors=TABLE_ILLUMINA_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=TABLE_ILLUMINA_ALGOS, graph=TABLE_ILLUMINA_GRAPHS, head=TABLE_ILLUMINA_GRAPH_HEADS, N=TABLE_ILLUMINA_Ns, m=TABLE_ILLUMINA_ms, seq_technology=TABLE_ILLUMINA_SEQ_TECHNOLOGY, errors=TABLE_ILLUMINA_errors),
    output:
        "results/TABLE_ILLUMINA_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=TABLE_ILLUMINA_ALGOS, graph=TABLE_ILLUMINA_GRAPHS, head=TABLE_ILLUMINA_GRAPH_HEADS, N=TABLE_ILLUMINA_Ns, m=TABLE_ILLUMINA_ms, seq_technology=TABLE_ILLUMINA_SEQ_TECHNOLOGY, errors=TABLE_ILLUMINA_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"

rule table_hifi_exp:
    input:
        refs = expand("graphs/"+graph_params+".fa", graph=TABLE_HIFI_GRAPHS, head=TABLE_HIFI_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=TABLE_HIFI_ALGOS, graph=TABLE_HIFI_GRAPHS, head=TABLE_HIFI_GRAPH_HEADS, N=TABLE_HIFI_Ns, m=TABLE_HIFI_ms, seq_technology=TABLE_HIFI_SEQ_TECHNOLOGY, errors=TABLE_HIFI_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=TABLE_HIFI_ALGOS, graph=TABLE_HIFI_GRAPHS, head=TABLE_HIFI_GRAPH_HEADS, N=TABLE_HIFI_Ns, m=TABLE_HIFI_ms, seq_technology=TABLE_HIFI_SEQ_TECHNOLOGY, errors=TABLE_HIFI_errors),
    output:
        "results/TABLE_HIFI_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=TABLE_HIFI_ALGOS, graph=TABLE_HIFI_GRAPHS, head=TABLE_HIFI_GRAPH_HEADS, N=TABLE_HIFI_Ns, m=TABLE_HIFI_ms, seq_technology=TABLE_HIFI_SEQ_TECHNOLOGY, errors=TABLE_HIFI_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"

rule refsize_exp:
    input:
        refs = expand("graphs/"+graph_params+".fa", graph=REF_SIZE_GRAPHS, head=REF_SIZE_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=REF_SIZE_ALGOS, graph=REF_SIZE_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms, seq_technology=REF_SIZE_SEQ_TECHNOLOGY, errors=REF_SIZE_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=REF_SIZE_ALGOS, graph=REF_SIZE_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms, seq_technology=REF_SIZE_SEQ_TECHNOLOGY, errors=REF_SIZE_errors),
    output:
        "results/REF_SIZE_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=REF_SIZE_ALGOS, graph=REF_SIZE_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms, seq_technology=REF_SIZE_SEQ_TECHNOLOGY, errors=REF_SIZE_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule readlen_exp:
    input:
        refs = expand("graphs/"+graph_params+".gfa", graph=READLEN_GRAPHS, head=READLEN_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=READLEN_ALGOS, graph=READLEN_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms, seq_technology=READLEN_SEQ_TECHNOLOGY, errors=READLEN_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=READLEN_ALGOS, graph=READLEN_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms, seq_technology=READLEN_SEQ_TECHNOLOGY, errors=READLEN_errors),
#        file = [("results/{algo}/"+params+"/benchmark.txt").format(**locals()) for algo in READLEN_ALGOS for graph in READLEN_GRAPHS for head in READLEN_GRAPH_HEADS for N in READLEN_Ns for m in READLEN_ms for seq_technology in READLEN_SEQ_TECHNOLOGY for errors in READLEN_errors
#            if not (algo == "graphaligner" and m >= 15000)]
    output:
        "results/READLEN_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=READLEN_ALGOS, graph=READLEN_GRAPHS, head=READLEN_GRAPH_HEADS, N=READLEN_Ns, m=READLEN_ms, seq_technology=READLEN_SEQ_TECHNOLOGY, errors=READLEN_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule ablation_exp:
    input:
        refs = expand("graphs/"+graph_params+".fa", graph=ABLATION_GRAPHS, head=ABLATION_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=ABLATION_ALGOS, graph=ABLATION_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms, seq_technology=ABLATION_SEQ_TECHNOLOGY, errors=ABLATION_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ABLATION_ALGOS, graph=ABLATION_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms, seq_technology=ABLATION_SEQ_TECHNOLOGY, errors=ABLATION_errors),
    output:
        "results/ABLATION_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=ABLATION_ALGOS, graph=ABLATION_GRAPHS, head=ABLATION_GRAPH_HEADS, N=ABLATION_Ns, m=ABLATION_ms, seq_technology=ABLATION_SEQ_TECHNOLOGY, errors=ABLATION_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule errorrate_exp:
    input:
        refs = expand("graphs/"+graph_params+".fa", graph=ERRORRATE_GRAPHS, head=ERRORRATE_GRAPH_HEADS),
        reads = expand("reads/"+params+"/reads.fq", algo=ERRORRATE_ALGOS, graph=ERRORRATE_GRAPHS, head=ERRORRATE_GRAPH_HEADS, N=ERRORRATE_Ns, m=ERRORRATE_ms, seq_technology=ERRORRATE_SEQ_TECHNOLOGY, errors=ERRORRATE_errors),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ERRORRATE_ALGOS, graph=ERRORRATE_GRAPHS, head=ERRORRATE_GRAPH_HEADS, N=ERRORRATE_Ns, m=ERRORRATE_ms, seq_technology=ERRORRATE_SEQ_TECHNOLOGY, errors=ERRORRATE_errors),
    output:
        "results/ERRORRATE_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}\t{seq_technology}\t{errors}", algo=ERRORRATE_ALGOS, graph=ERRORRATE_GRAPHS, head=ERRORRATE_GRAPH_HEADS, N=ERRORRATE_Ns, m=ERRORRATE_ms, seq_technology=ERRORRATE_SEQ_TECHNOLOGY, errors=ERRORRATE_errors)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

#rule trie_exp:
#    input:
#        expand("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE", D=range(6, 17))
#    output:
#        "results/TRIE_DUMMY"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute trie_experiment.ipynb > {output}"
#
#rule trie_exp:
#    input:
#        "results/aggregated_benchmarks.csv"
#    output:
#        dir = directory("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}/"),
#        dummy = "results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE"
#    shell:
#        "{ASTARIX_BIN} align-optimal -D {wildcards.D} -t 1 -g graphs/ecoli_head1000000_linear.gfa -q reads/ecoli_head1000000_N1000_m100/illumina.fq -o {output.dir} && touch {output.dummy}"

#rule aggregate_benchmarks:
#    input:
#        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms),
#    output:
#        "results/aggregated_benchmarks.csv"
#    params:
#        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"

#rule aggregate_exp:
#    input:
#        file = expand("results/{algo}/{graph}/benchmark.txt", algo=ALGOS, graph=EXPERIMENT_GRAPHS),
#    output:
#        "results/aggregated_experiments.csv"
#    params:
#        prefix = expand("{algo}\t{graph}", algo=ALGOS, graph=EXPERIMENT_GRAPHS)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{EXPERIMENT_FIRST_ROW}\\n/' > {output}"

#rule visualization_notebook:
#    input:
#        aggregated_benchmarks = "results/aggregated_benchmarks.csv",
#    output:
#        "results/VISUALIZATION_RAN"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute visualization.ipynb > {output}"

rule astar_prefix_vs_seeds:
    input:
        astar_prefix_align = "results/astarix-prefix/MHC1/out/alignments.tsv",
        astar_seeds_align = "results/astarix-seeds/MHC1/out/alignments.tsv"
    output:
        "results/PREFIX_VS_SEEDS_RAN"
    shell:
        "jupyter nbconvert --to notebook --inplace --execute astar_vs_dijkstra.ipynb > {output}"

rule astarix_prefix:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-prefix/"+params+"/out/alignments.tsv",
        file = "results/astarix-prefix/"+params+"/summary.txt"
    benchmark:
        "results/astarix-prefix/"+params+"/benchmark.txt"
    log:
        "results/astarix-prefix/"+params+"/log.txt"
    shell:
        ASTARIX_PREFIX_CMD

rule astarix_prefix_illumina:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-prefix-illumina/"+params+"/out/alignments.tsv",
        file = "results/astarix-prefix-illumina/"+params+"/summary.txt"
    benchmark:
        "results/astarix-prefix-illumina/"+params+"/benchmark.txt"
    log:
        "results/astarix-prefix-illumina/"+params+"/log.txt"
    shell:
        ASTARIX_PREFIX_ILLUMINA_CMD

rule astarix_seeds_exact:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_CMD

rule astarix_seeds_illumina:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds-illumina/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds-illumina/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds-illumina/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds-illumina/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_ILLUMINA_CMD

rule astarix_seeds_wo_match_pos:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds_wo_match_pos/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_match_pos/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds_wo_match_pos/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_match_pos/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_MATCH_POS_CMD

rule astarix_seeds_wo_skip_near_crumbs_pos:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_skip_near_crumbs_pos/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_SKIP_NEAR_CRUMBS_CMD

rule astarix_seeds_wo_opt:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds_wo_opt/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds_wo_opt/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds_wo_opt/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds_wo_opt/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_EXACT_WO_OPT_CMD

rule astarix_seeds_approx:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/astarix-seeds-approx/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds-approx/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds-approx/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds-approx/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_APPROX_CMD

rule dijkstra:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph = "graphs/"+graph_params+".gfa"
    output:
        align = "results/dijkstra/"+params+"/out/alignments.tsv",
        file = "results/dijkstra/"+params+"/summary.txt"
    benchmark:
        "results/dijkstra/"+params+"/benchmark.txt"
    log:
        "results/dijkstra/"+params+"/log.txt"
    shell:
        DIJKSTRA_CMD

rule vargas:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_gdef = "graphs/"+graph_params+".gdef"
    output:
        align = "results/vargas/"+params+"/out/alignments.tsv",
        file = "results/vargas/"+params+"/summary.txt"
    benchmark:
        "results/vargas/"+params+"/benchmark.txt"
    log:
        "results/vargas/"+params+"/log.txt"
    shell:
        VARGAS_CMD

rule prepare_vargas_graph:
    input:
        "graphs/"+graph_params+".fa"
    output:
        "graphs/"+graph_params+".gdef"
    shell:
        "{VARGAS_BIN} define -f {input} -t {output}"

rule graphaligner:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_vg = "graphs/"+graph_params+".vg"
    output:
        file = "results/graphaligner/"+params+"/summary.txt"
    benchmark:
        "results/graphaligner/"+params+"/benchmark.txt"
    log:
        "results/graphaligner/"+params+"/log.txt"
    shell:
        GA_CMD

rule pasgal:
    input:
        reads = "reads/"+params+"/reads.fq",
        graph_vg = "graphs/"+graph_params+".vg"
    output:
        file = "results/pasgal/"+params+"/summary.txt"
    benchmark:
        "results/pasgal/"+params+"/benchmark.txt"
    log:
        "results/pasgal/"+params+"/log.txt"
    shell:
        PASGAL_CMD

rule vg:
	input: **aligners_inputs
	output:
		file = "results/vg/"+params+"/summary.txt",
		align = "results/vg/"+params+"/alignments.tsv"
	benchmark:
		"results/vg/"+params+"/benchmark.txt"
	shell:
		#{TIMELIMIT} 
		"while mapfile -t -n 4 ary && ((${{#ary[@]}})); do {VG_BIN} align -s \"${{ary[1]}}\" {input.graph_vg} -j; done <{input.reads} >{output.align} 2>{output.file} {TIMEOUTPRINT}"

rule vg2gfa:
    input:
        "raw/PaSGAL/{prefix}.vg"
    output:
        "graphs/pasgal-{prefix}.gfa"
    shell:
        "{VG_BIN} view {input} > {output}"

## Chronological order of execution follows. ##

rule clean:
    shell:
        "rm -rf reads graphs graphs"

rule download_ecoli:
    output:
        protected("raw/ecoli.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-40/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz"),
        shell("gunzip Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz")
        shell("cut -d ' ' -f 1 < Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa >{output}")

rule download_chr1:
    output:
        protected("raw/chr1.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("gunzip Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("cut -d ' ' -f 1 < Homo_sapiens.GRCh38.dna.chromosome.1.fa | sed 's/[nN]//g' >{output}")

#rule download_PaSGAL_data:
#    output:
#        protected("raw/PaSGAL/{file}")
#    shadow: "shallow"
#    run:
#        shell("wget {PaSGAL_DATA_URL}/{wildcards.file} -O {output}")

rule fa2prefix:
    input:
        "raw/{graph}.fa"
    output:
        "graphs/"+graph_params+".fa"
    run:
        if int(wildcards.head) > 0:
            shell("head -c {wildcards.head} {input} >{output}")
        else:
            shell("cp {input} {output}")
        #"echo -n 'S\t1\t' >{output} && tail -n +2 {input} | tr -d '\n' >>{output}"
        #"| head -c {wildcards.head} >>{output}"

#ruleorder generate_pasgal_graph > create_linear_graph

#rule generate_pasgal_graph:
#    input:
#        "raw/PaSGAL/{graph}.vg"
#    output:
#        vg = "graphs/graph{graph}_head0.vg"
#    shell:
#        "cp {input} {output.gfa}"

# make PaSGAL happy: add a fictive segment

rule fa2gfa_vg:
    input:
        "graphs/"+graph_params+".fa"
    output:
        gfa = "graphs/"+graph_params+".gfa",
        vg = "graphs/"+graph_params+".vg"
    run:
        if int(wildcards.head) > 0:
            shell("echo -n 'S\t1\t' >{output.gfa} && tail -n +2 {input} | tr -d '\n' >>{output.gfa} && echo -n '\nS\t2\tA\nL\t1\t+\t2\t+\t0M\n' >>{output.gfa}")
        else:
            shell("cp raw/{wildcards.graph}.gfa {output.gfa}")
        shell("{VG_BIN} view -Fv {output.gfa} >{output.vg}")
		
# art_illumina -ss MSv3 -i ecoli.fasta -l 20 -c 10000 -o tmp
#    "reads/"+params+"/reads.fq"

rule simulate_illumina_reads:
    input:
        "graphs/"+graph_params+".fa"
    params:
        prefix = "reads/"+graph_params+"_N{N}_m{m}_illumina_errors{errors}/reads"
    output:
        "reads/"+graph_params+"_N{N}_m{m}_illumina_errors{errors}/reads.fq"
    shadow: "shallow"
    shell:
        "{ART} -ss MSv3 -sam -i {input} -c {wildcards.N} -l {wildcards.m} -o {params.prefix} --rndSeed 42"

#rule simulate_ccs_reads:
#	input:
#		"graphs/"+graph_params+".fa"
#	params:
#		prefix = "reads/"+graph_params+"_N{N}_m{m}_ccs/reads"
#	output:
#		"reads/"+graph_params+"_N{N}_m{m}_ccs/reads.fq"
#	shadow: "shallow"
#	run:
#		shell("{PBSIM} --data-type CLR --depth 0.02 --model_qc pbsim_profiles/model_qc_clr --length-min {wildcards.m} --length-max {wildcards.m} --length-mean {wildcards.m} --accuracy-min 0.99 --accuracy-sd 0 --accuracy-mean 1 {input}")
#		#shell("{PBSIM} --hmm_model pbsim_models/P4C2.model --depth 0.001 --accuracy-min 0.99 --accuracy-max 0.99 --accuracy-mean 0.99 --accuracy-sd 0 --length-mean {wildcards.m} --length-sd 0 {input}")
#		#"{PBSIM} --sample-fastq pbsim_sample.fastq --depth 0.001 --accuracy-min 0.98 --accuracy-max 0.98 --length-mean {wildcards.m} --length-sd 0 {input}"
#		#"{PBSIM} --data-type CCS --depth 0.001 --model_qc pbsim_profiles/model_qc_ccs --length-mean {wildcards.m} --length-sd 0 {input}"
#		shell("cp -L sd_0001.fastq {params.prefix}.fq")
#		shell("cp -L sd_0001.maf {params.prefix}.maf")
#		shell("cp -L sd_0001.ref {params.prefix}.ref")

rule simulate_hifi_reads_fixed_len:
	input:
		"graphs/"+graph_params+".fa"
	params:
		prefix = "reads/"+graph_params+"_N{N}_m{m}_hifi_errors{errors}/reads"
	output:
		"reads/"+graph_params+"_N{N}_m{m}_hifi_errors{errors}/reads.fq"
	shadow: "shallow"
	shell:
		#"{RANDOMREADS} -Xmx1g build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin={wildcards.errors} pbmax={wildcards.errors} reads={wildcards.N} paired=f gaussianlength=t minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"
		"{RANDOMREADS} -Xmx1g build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin={wildcards.errors} pbmax={wildcards.errors} coverage={wildcards.N} paired=f gaussianlength=t minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"
		#"{RANDOMREADS} -Xmx1g build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin={wildcards.errors} pbmax={wildcards.errors} coverage=$(echo 'scale=5; {wildcards.N}*1000000/{wildcards.head}' | bc) paired=f gaussianlength=t minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"
		#"{RANDOMREADS} -Xmx1g build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin={wildcards.errors} pbmax={wildcards.errors} coverage=1 paired=f gaussianlength=t minlength={wildcards.m} midlength={wildcards.m} maxlength={wildcards.m} out={output}"

rule simulate_hifi_reads_natural:
	input:
		"graphs/"+graph_params+".fa"
	params:
		prefix = "reads/"+graph_params+"_N{N}_m{m}_hifi-natural_errors{errors}/reads"
	output:
		"reads/"+graph_params+"_N{N}_m{m}_hifi-natural_errors{errors}/reads.fq"
	shadow: "shallow"
	shell:
		"{RANDOMREADS} -Xmx1g build=1 ow=t seed=1 ref={input} illuminanames=t addslash=t pacbio=t pbmin={wildcards.errors} pbmax={wildcards.errors} coverage={wildcards.N} paired=f gaussianlength=t minlength=5000 midlength=13000 maxlength=25000 out={output}"

rule head_reads:
    input:
        "raw/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

rule head_pasgal_reads:
    input:
        "raw/PaSGAL/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

