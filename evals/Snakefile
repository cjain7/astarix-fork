configfile: "snakemake_config.yaml"
BCALM = config["bcalm_bin_path"]
BCALMCONVERTPATH = config["bcalm_convert_path"]
ART = config["art_bin_path"]

ASTARIX_BIN = config["astarix_bin_path"]
GA_BIN = config["graphaligner_bin_path"]
PASGAL_BIN = config["pasgal_bin_path"]
VG_BIN = config["vg_bin_path"]
VARGAS_BIN = config["vargas_bin_path"]

TIMELIMIT       = "(timeout 1800s"
TIMEOUTPRINT    = ") || ([ $? -eq 124 ] && echo timeouted)"

ASTARIX_PREFIX_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-prefix -q {input.reads} -g {input.graph} -d 5 -M 0 -S 1 -G 5 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
ASTARIX_SEEDS_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a astar-seeds -q {input.reads} -g {input.graph} -M 0 -S 1 -G 5 --fixed_trie_depth 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
DIJKSTRA_CMD = "{TIMELIMIT} {ASTARIX_BIN} align-optimal -a dijkstra -q {input.reads} -g {input.graph} -M 0 -S 1 -G 1 -o $(dirname {output.align}) >{output.file} {TIMEOUTPRINT} >>{output.file}"
GA_CMD = "{TIMELIMIT} {GA_BIN} --seeds-first-full-rows 64 -b 10000 -a alignments.gaf -f {input.reads} -g {input.graph_vg} >{output.file} {TIMEOUTPRINT} >>{output.file}"
PASGAL_CMD = "{TIMELIMIT} {PASGAL_BIN} -m vg -r {input.graph_vg} -q {input.reads} -t 1 -o {output.file} {TIMEOUTPRINT} >>{output.file}"
VARGAS_CMD = "{TIMELIMIT} {VARGAS_BIN} align -g {input.graph_gdef} -U {input.reads} --ete >{output.align} 2>{output.file} {TIMEOUTPRINT}"
### VG_CMD = inlined ### "{TIMELIMIT} {VG_BIN} align -s \"${ary[1]}\" {input.graph_vg} >{output.align} 2>{output.file} {TIMEOUTPRINT}"

PaSGAL_DATA_URL = "https://alurulab.cc.gatech.edu/sites/all/projectFiles/PaSGAL_Chirag"
PaSGAL_FILES = ["L1.fa", "L2.fastq", "L3.fastq",
                "M1.fa", "M2.fastq", "M3.fastq",
                "LRC.vg", "MHC1.vg", "MHC2.txt"]

# params

REF_SIZE_ALGOS          = ["astarix-seeds", "astarix-prefix", "vargas", "graphaligner", "vg", "pasgal", "dijkstra"]
REF_SIZE_SCALING_GRAPHS = ["ecoli"]
REF_SIZE_GRAPH_HEADS    = [10000, 100000, 1000000, 10000000]
REF_SIZE_Ns             = [10000]
REF_SIZE_ms             = [100]

NUMREADS_ALGOS          = ["astarix-seeds", "astarix-prefix", "vargas"] #, "graphaligner"]
NUMREADS_SCALING_GRAPHS = ["ecoli"]
NUMREADS_GRAPH_HEADS    = [1000000000]
NUMREADS_Ns             = [1000, 10000, 100000, 1000000]
NUMREADS_ms             = [100]

GRAPHS       = [ "ecoli" ] #"chr1" ]# "ecoli" ]
ALGOS        = ["astarix-seeds", "astarix-prefix" ] # [ "pasgal", "astarix", "dijkstra", "graphaligner" ] # ] #, "dijkstra", "graphaligner" ] #"vg" ] $"pasgal"
GRAPH_HEADS_SMALL  = [10000, 100000, 1000000, 10000000]  # up to current exact state-of-the-art
GRAPH_HEADS_BIG    = [10000000, 100000000, 100000000]
GRAPH_HEADS = GRAPH_HEADS_SMALL #+ GRAPH_HEADS_BIG
Ns           = [10000] #, 1000, 10000]       # number of reads
ms           = [100] #75] #, 100, 150, 250]          # read len

FIRST_ROW       = "algo\tgraph\thead\tN\tm\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
AGGREGATED_BENCHMARKS = "results/aggregated_benchmarks.csv"
AGGREGATED_EXPERIMENTS = "results/aggregated_experiments.csv"

graph_params = "{graph}_head{head}"
read_params = "N{N}_m{m}"
params = graph_params + "_" + read_params

EXPERIMENT_N = 1000 #20000
EXPERIMENT_FIRST_ROW       = "algo\tgraph\ts\th:m:s\tmax_rss\tmax_vms\tmax_uss\tmax_pss\tio_in\tio_out\tmean_load"
EXPERIMENT_GRAPHS = ["MHC1", "LRC"]
EXPERIMENT_READS = { "MHC1": "M1", "LRC": "L1", "ecoli": "ecoli"}
experiment_graph = "graphs/pasgal-{graph}.gfa"
experiment_graph_vg = "raw/PaSGAL/{graph}.vg"
experiment_input_reads = "raw/PaSGAL/{reads}.fa"

aligners_inputs = {
    'graph' : "graphs/"+graph_params+"_linear.gfa",
    'graph_vg' : "graphs/"+graph_params+"_linear.vg",
    'reads' : "reads/"+params+"/illumina.fq"
}

## Default summary rule to be satisfied.
rule all:
    input:
#        agg1 = "results/aggregated_benchmarks.csv"
        ref_size = "results/REF_SIZE_SCALING_DONE",
#        numreads = "results/NUMREADS_SCALING_DONE"
#        astar_prefix_vs_seeds = "results/PREFIX_VS_SEEDS_RAN",
#        visualization = "results/VISUALIZATION_RAN",
#        agg2 = "results/aggregated_experiments.csv",
#        trie = "results/TRIE_DUMMY"

rule run_ref_size_scaling_experiment:
    input:
        refs = expand("prefixes/"+graph_params+".fa", graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS),
        reads = expand("reads/"+params+"/illumina.fq", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms),
    output:
        "results/REF_SIZE_SCALING_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=REF_SIZE_ALGOS, graph=REF_SIZE_SCALING_GRAPHS, head=REF_SIZE_GRAPH_HEADS, N=REF_SIZE_Ns, m=REF_SIZE_ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

rule run_numreads_scaling_experiment:
    input:
        refs = expand("prefixes/"+graph_params+".fa", graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS),
        reads = expand("reads/"+params+"/illumina.fq", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms),
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms),
    output:
        "results/NUMREADS_SCALING_DONE"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=NUMREADS_ALGOS, graph=NUMREADS_SCALING_GRAPHS, head=NUMREADS_GRAPH_HEADS, N=NUMREADS_Ns, m=NUMREADS_ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"
#        "jupyter nbconvert --to notebook --inplace --execute ref_size_scaling.ipynb >{output}"

#rule trie_experiments:
#    input:
#        expand("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE", D=range(6, 17))
#    output:
#        "results/TRIE_DUMMY"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute trie_experiment.ipynb > {output}"
#
#rule trie_experiment:
#    input:
#        "results/aggregated_benchmarks.csv"
#    output:
#        dir = directory("results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}/"),
#        dummy = "results/trie_experiment_big/ecoli_head1000000_linear/astar-D{D}_TRIE_DONE"
#    shell:
#        "{ASTARIX_BIN} align-optimal -D {wildcards.D} -t 1 -g graphs/ecoli_head1000000_linear.gfa -q reads/ecoli_head1000000_N1000_m100/illumina.fq -o {output.dir} && touch {output.dummy}"

rule aggregate_benchmarks:
    input:
        file = expand("results/{algo}/"+params+"/benchmark.txt", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms),
    output:
        "results/aggregated_benchmarks.csv"
    params:
        prefix = expand("{algo}\t{graph}\t{head}\t{N}\t{m}", algo=ALGOS, graph=GRAPHS, head=GRAPH_HEADS, N=Ns, m=ms)
    shell:
        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{FIRST_ROW}\\n/' > {output}"

#rule aggregate_experiments:
#    input:
#        file = expand("results/{algo}/{graph}/benchmark.txt", algo=ALGOS, graph=EXPERIMENT_GRAPHS),
#    output:
#        "results/aggregated_experiments.csv"
#    params:
#        prefix = expand("{algo}\t{graph}", algo=ALGOS, graph=EXPERIMENT_GRAPHS)
#    shell:
#        "paste <(echo \"{params.prefix}\" | tr ' ' '\n') <(tail -n 1 --silent {input.file}) | sed '1s/^/{EXPERIMENT_FIRST_ROW}\\n/' > {output}"

#rule visualization_notebook:
#    input:
#        aggregated_benchmarks = "results/aggregated_benchmarks.csv",
#    output:
#        "results/VISUALIZATION_RAN"
#    shell:
#        "jupyter nbconvert --to notebook --inplace --execute visualization.ipynb > {output}"

rule astar_prefix_vs_seeds:
    input:
        astar_prefix_align = "results/astarix-prefix/MHC1/out/alignments.tsv",
        astar_seeds_align = "results/astarix-seeds/MHC1/out/alignments.tsv"
    output:
        "results/PREFIX_VS_SEEDS_RAN"
    shell:
        "jupyter nbconvert --to notebook --inplace --execute astar_vs_dijkstra.ipynb > {output}"

rule benchmark_astarix_prefix:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-prefix/"+params+"/out/alignments.tsv",
        file = "results/astarix-prefix/"+params+"/summary.txt"
    benchmark:
        "results/astarix-prefix/"+params+"/benchmark.txt"
    log:
        "results/astarix-prefix/"+params+"/log.txt"
    shell:
        ASTARIX_PREFIX_CMD

rule benchmark_astarix_seeds:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/astarix-seeds/"+params+"/out/alignments.tsv",
        file = "results/astarix-seeds/"+params+"/summary.txt"
    benchmark:
        "results/astarix-seeds/"+params+"/benchmark.txt"
    log:
        "results/astarix-seeds/"+params+"/log.txt"
    shell:
        ASTARIX_SEEDS_CMD

rule benchmark_dijkstra:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph = "prefixes/"+graph_params+".fa"
    output:
        align = "results/dijkstra/"+params+"/out/alignments.tsv",
        file = "results/dijkstra/"+params+"/summary.txt"
    benchmark:
        "results/dijkstra/"+params+"/benchmark.txt"
    log:
        "results/dijkstra/"+params+"/log.txt"
    shell:
        DIJKSTRA_CMD

#rule benchmark_dijkstra:
#    input:
#        reads = lambda wlc: "reads/"+EXPERIMENT_READS[wlc.graph]+"_reads"+str(EXPERIMENT_N)+".fa",
#        graph = "graphs/pasgal-{graph}.gfa",
#    output:
#        align = "results/dijkstra/{graph}/out/alignments.tsv",
#        file = "results/dijkstra/{graph}/summary.txt"
#    benchmark:
#        "results/dijkstra/{graph}/benchmark.txt"
#    log:
#        "results/dijkstra/{graph}/log.txt"
#    shell:
#        DIJKSTRA_CMD

rule benchmark_vargas:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph_gdef = "prefixes/"+graph_params+".gdef"
    output:
        align = "results/vargas/"+params+"/out/alignments.tsv",
        file = "results/vargas/"+params+"/summary.txt"
    benchmark:
        "results/vargas/"+params+"/benchmark.txt"
    log:
        "results/vargas/"+params+"/log.txt"
    shell:
        VARGAS_CMD

rule prepare_vargas_graph:
    input:
        "prefixes/"+graph_params+".fa"
    output:
        "prefixes/"+graph_params+".gdef"
    shell:
        "{VARGAS_BIN} define -f {input} -t {output}"

rule benchmark_graphaligner:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph_vg = "graphs/"+graph_params+"_linear.vg"
        #graph = "prefixes/"+graph_params+".fa"
    output:
        file = "results/graphaligner/"+params+"/summary.txt"
    benchmark:
        "results/graphaligner/"+params+"/benchmark.txt"
    log:
        "results/graphaligner/"+params+"/log.txt"
    shell:
        GA_CMD

rule benchmark_pasgal:
    input:
        reads = "reads/"+params+"/illumina.fq",
        graph_vg = "graphs/"+graph_params+"_linear.vg"
        #reads = lambda wlc: "reads/"+EXPERIMENT_READS[wlc.graph]+"_reads"+str(EXPERIMENT_N)+".fa",
        #graph = "graphs/pasgal-{graph}.gfa",
    output:
        file = "results/pasgal/"+params+"/summary.txt"
    benchmark:
        "results/pasgal/"+params+"/benchmark.txt"
    log:
        "results/pasgal/"+params+"/log.txt"
    shell:
        PASGAL_CMD

rule vg2gfa:
    input:
        "raw/PaSGAL/{prefix}.vg"
    output:
        "graphs/pasgal-{prefix}.gfa"
    shell:
        "{VG_BIN} view {input} > {output}"

## Chronological order of execution follows. ##

rule clean:
    shell:
        "rm -rf reads graphs prefixes"

rule download_ecoli:
    output:
        protected("raw/ecoli.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-40/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz"),
        shell("gunzip Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz")
        shell("cut -d ' ' -f 1 < Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa >{output}")

rule download_chr1:
    output:
        protected("raw/chr1.fa")
    shadow: "shallow"
    run:
        shell("wget ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("gunzip Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz"),
        shell("cut -d ' ' -f 1 < Homo_sapiens.GRCh38.dna.chromosome.1.fa | sed 's/[nN]//g' >{output}")

rule download_PaSGAL_data:
    output:
        protected("raw/PaSGAL/{file}")
    shadow: "shallow"
    run:
        shell("wget {PaSGAL_DATA_URL}/{wildcards.file} -O {output}")

rule create_genome_prefix:
    input:
        "raw/{graph}.fa"
    output:
        "prefixes/"+graph_params+".fa"
    run:
        if {wildcards.head}:
            shell("head -c {wildcards.head} {input} >{output}")
        else:
            shell("cp {input} {output}")
        #"echo -n 'S\t1\t' >{output} && tail -n +2 {input} | tr -d '\n' >>{output}"
        #"| head -c {wildcards.head} >>{output}"

rule create_linear_graph:
    input:
        "prefixes/"+graph_params+".fa"
    output:
        gfa = "graphs/"+graph_params+"_linear.gfa",
        vg = "graphs/"+graph_params+"_linear.vg"
    shell:
        "echo -n 'S\t1\t' >{output.gfa} && tail -n +2 {input} | tr -d '\n' >>{output.gfa} && echo -n '\nS\t2\tA\nL\t1\t+\t2\t+\t0M\n' >>{output.gfa}"  # make PaSGAL happy: add a fictive segment
        "&& {VG_BIN} view -Fv {output.gfa} >{output.vg}"

rule generate_illumina_reads:
    input:
        "prefixes/"+graph_params+".fa"
    params:
        prefix = "reads/"+params+"/illumina"
    output:
        "reads/"+params+"/illumina.fq"
    shadow: "shallow"
    shell:
        "{ART} -ss HS25 -sam -i {input} -c {wildcards.N} -l {wildcards.m} -o {params.prefix} --rndSeed 42"

#ruleorder: head_ecoli_reads > head_reads

rule head_reads:
    input:
        "raw/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

#rule head_ecoli_reads:
#    input:
#        "raw/ecoli.fasta"
#    output:
#        "reads/ecoli_reads{reads_num}.fq"
#    shell:
#        "{ART} -ss HS25 -sam -i {input} -c {wildcards.N} -l {wildcards.m} -o {params.prefix} --rndSeed 42"

rule head_pasgal_reads:
    input:
        "raw/PaSGAL/{reads_file}.fa"
    output:
        "reads/{reads_file}_reads{reads_num}.fa"
    shell:
        "head -n $(( 2 * {wildcards.reads_num} )) {input} >{output}"

#rule run_astarix_prefix:
#    input: **aligners_inputs
#    output:
#        file = "results/astarix-prefix/"+params+"/summary.txt",
#        align = "results/astarix-prefix/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/astarix-prefix/"+params+"/benchmark.txt"
#    log:
#        "results/astarix-prefix/"+params+"/log.txt"
#    shell:
#        ASTARIX_PREFIX_CMD
#
#rule run_astarix_seeds:
#    input: **aligners_inputs
#    output:
#        file = "results/astarix-seeds/"+params+"/summary.txt",
#        align = "results/astarix-seeds/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/astarix-seeds/"+params+"/benchmark.txt"
#    log:
#        "results/astarix-seeds/"+params+"/log.txt"
#    shell:
#        ASTARIX_SEEDS_CMD
#
#rule run_dijkstra:
#    input: **aligners_inputs
#    output:
#        file = "results/dijkstra/"+params+"/summary.txt",
#        align = "results/dijkstra/"+params+"/out/alignments.tsv"
#    benchmark:
#        "results/dijkstra/"+params+"/benchmark.txt"
#    log:
#        "results/dijkstra/"+params+"/log.txt"
#    shell:
#        DIJKSTRA_CMD
#
#rule run_graphaligner:
#    input: **aligners_inputs
#    output:
#        file = "results/graphaligner/"+params+"/summary.txt"
#    benchmark:
#        "results/graphaligner/"+params+"/benchmark.txt"
#    log:
#        "results/graphaligner/"+params+"/log.txt"
#    shell:
#        GA_CMD
#
#rule run_pasgal:
#    input: **aligners_inputs
#    output:
#        file = "results/pasgal/"+params+"/summary.txt"
#    benchmark:
#        "results/pasgal/"+params+"/benchmark.txt"
#    log:
#        "results/pasgal/"+params+"/log.txt"
#    shell:
#        PASGAL_CMD

rule run_vg:
	input: **aligners_inputs
	output:
		file = "results/vg/"+params+"/summary.txt",
		align = "results/vg/"+params+"/alignments.tsv"
	benchmark:
		"results/vg/"+params+"/benchmark.txt"
	shell:
		"while mapfile -t -n 4 ary && ((${{#ary[@]}})); do {VG_BIN} align -s \"${{ary[1]}}\" {input.graph_vg} -j; done <{input.reads} >{output.align} 2>{output.file}"
		#query = "AAACGT",
		#shell(VG_CMD)
